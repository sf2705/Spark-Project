# Sparkify Project

### Notes:

1. There is a blog post in [Medium - Sparkify Project](https://siqifeng.medium.com/predict-churn-of-sparkify-b58f29f08a7)


#### 1. Installations

Python: 3.8.5

Spark: spark-3.0.1-bin-hadoop2.7

Java: 1.8.0_271

#### 2. Libraries used

pyspark

SparkConf, SparkContext -- from pyspark

SparkSession, functions -- from pyspark.sql

udf, desc, isnan, when, count, col, countDistinct -- from pyspark.sql.functions

IntegerType -- from pyspark.sql.types

Correlation -- from pyspark.ml.stat

Pipeline -- from pyspark.ml

Normalizer,VectorAssembler, StringIndexer, StandardScaler -- from pyspark.ml.feature

LogisticRegression -- from pyspark.ml.classification

CrossValidator, ParamGridBuilder -- from pyspark.ml.tuning

BinaryClassificationEvaluator -- from pyspark.ml.evaluation

datetime

numpy

pandas

matplotlib.pyplot


#### 3. Project Motivation 

This project is aiming for identify customer churn in advance for Sparkify, a music streaming company. As a music streaming company, revenue is mainly generated by the users who like their service and would like to subscribe and pay for the songs. Therefore, it is crucial to identify the users that are potentially leaving them in advance. Then Sparkify can provide discount information or pop up notification on user end to show new features to enhance user experience. Hence, if we can build some machine learning model to predict user churn, it would make real impact on Sparkify.

#### 4. Technical details 

1. Initiate Spark session in Jupyter Notebook

2. Load and Clean data to drop invalid rows, which are defined as no userId or no sessionId
3. Data Exploration: explore the data and draw some plots to visualize data, to have a better understanding of our dataset in big picture
4. Modeling: we first use correlation matrix to explore relations between variables, then use logistric regression with cross validation to predict user churn
5. Evaluation: our model is mainly evaluated by F1 score. As there are chances that F1 is not available due to our small data size, we use other measurement like accuracy, AUC as reference.


#### 5. Files in Repository
Sparkify.ipynb 
README.md

#### 6.Results and Improvements

By comparing logistic regression model with different parameters and different ways of normalizing data, we achived AUC as 0.713 and F1 score as 0.33 in our validation set. By appying model to test set, we got AUC as 0.696 with accuracy 0.657. Unfortunately, we don't have a F1 score for our test data because both of our precision and recall is 0. We did not successfully identify any user churn in our test data.

Here are some improvements we can make in the future:

1. Train, Validate and Test on a larger amount of data. 
2. Feature selection: In current models, we only use web page interactions as our features, but we can perform a feature selection or PCA on many more variables to choose the features that are mostly related to churn.
3. Try more different models. We can also try to implement K-Nearest Neighbors or decision tree to see if there is any improvements.

#### 7.Licensing, Authors, Acknowledgements 

Data coming from Udacity Data Science Nano Program